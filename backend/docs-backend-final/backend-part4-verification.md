# ğŸ“Š BACKEND PHASE 4: VERIFICATION & VIBE-CODING GUIDE
## Logging, Monitoring & Deployment Checklist

---

## PHASE 4 OVERVIEW

**What You're Building**: Production observability + Docker deployment  
**Duration**: 2-3 hours  
**Status**: Building on Phases 1-3 âœ… foundation  
**Difficulty**: Medium (operations, Docker, monitoring)

---

## CRITICAL PHASE 4 CONCEPTS

### Structured Logging (JSON)

```
Development (pretty-printed):
  INFO Request started {method: GET, path: /api/v1/drifts}
  INFO Request completed {status: 200, duration: 45ms}

Production (JSON, machine-parseable):
  {"level":"info","msg":"Request started","method":"GET","path":"/api/v1/drifts","timestamp":"..."}
  {"level":"info","msg":"Request completed","status":200,"duration":45,"timestamp":"..."}
  
Benefits:
  âœ… Parseable by ELK, Datadog, Cloudflare, etc.
  âœ… Searchable by fields (userId, status, duration)
  âœ… Correlatable with trace IDs
  âœ… Aggregatable for metrics
```

### Correlation ID (Request Tracing)

```
Request 1:
  â”œâ”€ correlationId: "abc123"
  â”œâ”€ GET /drifts
  â”œâ”€ Service call
  â”œâ”€ DB query 1
  â”œâ”€ DB query 2
  â””â”€ Response: ALL logs have "abc123"

Benefit: Follow entire request flow through logs
```

### Prometheus Metrics

```
Types:
  Counter    â† Monotonically increasing (total requests)
  Histogram  â† Distribution over time (request latency)
  Gauge      â† Current value (connections, memory)

Collection:
  âœ… Request metrics (total, duration by status)
  âœ… Error metrics (by code, by path)
  âœ… Database metrics (query duration)
  âœ… Custom business metrics
  
Scraping:
  Prometheus â†’ GET /metrics â†’ Prometheus format
```

### Health Checks (Orchestration)

```
Liveness Probe (/health/live):
  âœ… Is process running?
  âœ… Simple, fast check
  âœ… Restart if fails

Readiness Probe (/health/ready):
  âœ… Can handle requests?
  âœ… Check dependencies (DB, cache, etc.)
  âœ… Remove from load balancer if fails
  âœ… Used during rolling deployments
```

### Docker Multi-Stage Build

```
Stage 1: Build
  â”œâ”€ Large Node image
  â”œâ”€ Install dependencies
  â”œâ”€ Compile TypeScript
  â””â”€ Result: ~1GB layer

Stage 2: Runtime
  â”œâ”€ Fresh alpine Node
  â”œâ”€ Copy only dist + node_modules
  â”œâ”€ No source code
  â”œâ”€ No dev dependencies
  â””â”€ Result: ~200MB final image
  
Result: Final image is small & secure
```

---

## PRE-IMPLEMENTATION CHECKLIST

**Before Antigravity starts**:

- [ ] Phase 3 API endpoints fully working
- [ ] WebSocket real-time events working
- [ ] `npm run type-check` â†’ 0 errors
- [ ] Database running with seed data
- [ ] Dependencies installed:
  ```bash
  npm install pino pino-pretty uuid prometheus
  npm install --save-dev @types/uuid
  ```
- [ ] Docker installed locally
- [ ] Understanding of JSON logging, metrics, health checks

---

## VIBE-CODING STANDARDS FOR PHASE 4

### Logging Standards (Critical)

```typescript
// âœ… CORRECT - Structured JSON logs
logger.info(
  {
    userId: user.id,
    driftId: drift.id,
    action: 'drift_approved',
    duration: 150,
  },
  'Drift approved'
);

// âœ… CORRECT - Error with full context
logger.error(
  {
    error: error.message,
    stack: error.stack,
    userId: user.id,
    driftId: drift.id,
    correlationId: req.correlationId,
  },
  'Failed to approve drift'
);

// âœ… CORRECT - Never log secrets
logger.info('User login', {
  userId: user.id,
  email: user.email,
  // NOT password, token, apiKey
});

// âŒ WRONG - Unstructured logs
logger.info('User ' + userId + ' approved drift ' + driftId);

// âŒ WRONG - Logging secrets
logger.info('Token created', { token: accessToken });

// âŒ WRONG - console.log instead of logger
console.log('Something happened');  // NO! Use logger

// âŒ WRONG - Too verbose in production
logger.debug('Inside loop iteration ' + i);  // Too much in prod
```

### Metrics Recording (Critical)

```typescript
// âœ… CORRECT - Record all operations
MetricsService.recordRequest(method, path, status, duration);
MetricsService.recordDatabaseQuery('SELECT', 'drifts', 25);
MetricsService.recordError(code, path);

// âœ… CORRECT - Observe all durations (not just success)
requestDuration.observe(150);  // Even slow requests
errorCounter.inc();  // All errors tracked

// âŒ WRONG - Only successful requests
if (success) {
  MetricsService.recordRequest(...);  // Missing failures!
}

// âŒ WRONG - Skipping error tracking
// Error happens but no metric recorded
```

### Configuration (Critical)

```typescript
// âœ… CORRECT - All config from environment
const port = parseInt(process.env.PORT || '3001', 10);
const secret = process.env.JWT_SECRET;

if (!secret && process.env.NODE_ENV === 'production') {
  throw new Error('JWT_SECRET required in production');
}

// âœ… CORRECT - Validate config at startup
validateConfig();  // Fail fast if config invalid

// âŒ WRONG - Hardcoded config
const port = 3001;
const secret = 'dev-secret';

// âŒ WRONG - Missing required config
const secret = process.env.JWT_SECRET;  // Could be undefined!
```

### Health Checks (Critical)

```typescript
// âœ… CORRECT - Comprehensive readiness check
router.get('/ready', async (req, res) => {
  try {
    // Check database
    await prisma.$queryRaw`SELECT 1`;
    
    res.status(200).json({ status: 'ready' });
  } catch (error) {
    res.status(503).json({ 
      status: 'not_ready',
      error: error.message 
    });
  }
});

// âœ… CORRECT - Simple liveness check
router.get('/live', (req, res) => {
  res.status(200).json({ status: 'alive' });
});

// âŒ WRONG - No dependency checks
router.get('/health', (req, res) => {
  res.status(200).json({ ok: true });  // Doesn't verify DB!
});

// âŒ WRONG - Readiness doesn't check DB
router.get('/ready', (req, res) => {
  res.status(200).json({ ready: true });  // Always true!
});
```

### Docker Standards (Critical)

```dockerfile
# âœ… CORRECT - Multi-stage build
FROM node:20-alpine AS builder
RUN npm ci
COPY . .
RUN npm run build

FROM node:20-alpine
COPY --from=builder /build/dist ./dist
COPY --from=builder /build/node_modules ./node_modules
USER node
HEALTHCHECK --interval=30s ...
CMD ["node", "dist/server.js"]

# âœ… CORRECT - Non-root user
USER node  # Security: not root

# âœ… CORRECT - Proper signal handling
ENTRYPOINT ["dumb-init", "--"]  # Handles SIGTERM

# âŒ WRONG - Single stage build (huge image)
FROM node:20
COPY . .
CMD ["npm", "start"]  # 1GB+ image!

# âŒ WRONG - Running as root
# No USER directive â†’ runs as root

# âŒ WRONG - No health check
# Docker doesn't know if app is healthy
```

### Graceful Shutdown (Critical)

```typescript
// âœ… CORRECT - Handle shutdown signals
process.on('SIGTERM', async () => {
  logger.info('Shutting down gracefully');
  
  // Stop accepting new requests
  server.close();
  
  // Close database connections
  await prisma.$disconnect();
  
  // Close WebSocket connections
  io.close();
  
  logger.info('Shutdown complete');
  process.exit(0);
});

// âŒ WRONG - No shutdown handling
// App force-kills, connections don't close
// In-flight requests get killed
// Database connections leak
```

---

## POST-IMPLEMENTATION VERIFICATION

### Step 1: TypeScript & Build

```bash
npm run type-check  # 0 errors
npm run build       # success
npm run dev         # server starts

# Expected in console:
# ğŸš€ Server started on port 3001
# ğŸ“¡ WebSocket ready
# âœ… Health check: /health/live, /health/ready
```

### Step 2: Health Checks

```bash
# Liveness (should always return 200)
curl http://localhost:3001/health/live
# { "status": "alive", "timestamp": "..." }

# Readiness (returns 503 if DB down)
curl http://localhost:3001/health/ready
# { "status": "ready", "checks": { "database": "ok" } }

# Detailed (includes memory, uptime)
curl http://localhost:3001/health/detailed
# { "status": "ok", "memory": {...}, "uptime": 120 }
```

### Step 3: Logging Verification

```bash
# Make a request
curl http://localhost:3001/api/v1/drifts

# Check logs for:
# âœ… JSON format (not string logs)
# âœ… "Request started" message
# âœ… "Request completed" message
# âœ… Correlation ID (x-correlation-id)
# âœ… Duration in milliseconds
# âœ… HTTP status code
```

### Step 4: Metrics Endpoint

```bash
# Get Prometheus metrics
curl http://localhost:3001/metrics

# Should contain:
# âœ… http_requests_total (counter)
# âœ… http_request_duration_ms (histogram)
# âœ… errors_total (counter)
# âœ… Prometheus format (not JSON)

# Example line:
# http_requests_total{method="GET",path="/drifts",status="200"} 5
```

### Step 5: Error Logging

```bash
# Trigger an error
curl -X POST http://localhost:3001/api/v1/drifts/invalid/approve \
  -H "Authorization: Bearer invalid" \
  -d '{}'

# Check logs for:
# âœ… Error level (not info)
# âœ… Error code (AUTH_ERROR, NOT_FOUND, etc.)
# âœ… Error message (without secrets)
# âœ… Stack trace
# âœ… Correlation ID
# âœ… Path, method, status
# âœ… No passwords, tokens, API keys logged
```

### Step 6: Docker Build

```bash
# Build image
docker build -t driftsentry:latest .

# Check:
# âœ… Build succeeds
# âœ… Image size < 500MB
# âœ… No source code in image
# âœ… No dev dependencies in image

# Check image size
docker images | grep driftsentry
# driftsentry latest ... ~300MB (good)
```

### Step 7: Docker Run

```bash
# Start container
docker run --rm \
  -e NODE_ENV=production \
  -e DATABASE_URL="postgresql://user:pass@host:5432/driftsentry" \
  -e JWT_SECRET="your-secret" \
  -p 3001:3001 \
  driftsentry:latest

# Expected:
# âœ… Container starts
# âœ… Server listens on port 3001
# âœ… No errors in logs
# âœ… Health check passes

# Test from another terminal
curl http://localhost:3001/health/live
# { "status": "alive" }
```

### Step 8: Docker Compose (Dev + Prod)

```bash
# Production stack
docker-compose -f docker-compose.prod.yml up

# Expected:
# âœ… App service starts
# âœ… PostgreSQL service starts
# âœ… Services connected to network
# âœ… App can reach database
# âœ… Logs are JSON structured

# Test
curl http://localhost:3001/api/v1/drifts
# Returns paginated drifts (connected to DB)
```

### Step 9: Configuration Validation

```bash
# Test missing critical config
docker run --rm \
  -e NODE_ENV=production \
  driftsentry:latest

# Expected:
# âŒ Exit with error
# "JWT_SECRET is required in production"

# Test with all config
docker run --rm \
  -e NODE_ENV=production \
  -e DATABASE_URL="..." \
  -e JWT_SECRET="secret" \
  driftsentry:latest

# Expected:
# âœ… Server starts
# âœ… Logs show "Configuration validated"
```

### Step 10: Graceful Shutdown

```bash
# Start server
npm run dev

# In another terminal, send SIGTERM
kill -TERM $(pgrep -f "node.*dist/server.js")

# Expected in logs:
# âœ… "Shutting down gracefully"
# âœ… "HTTP server closed"
# âœ… "Database disconnected"
# âœ… "Shutdown complete"
# âœ… Exit code 0

# Test timeout (kill -9 after 30s)
# If shutdown takes >30s, process force-kills
```

---

## SECURITY CHECKLIST

**Verify all 10 security requirements**:

- [ ] No secrets in Dockerfile
- [ ] Non-root user in container
- [ ] Proper signal handling (dumb-init)
- [ ] Health checks enabled
- [ ] Configuration validated at startup
- [ ] No hardcoded values
- [ ] Logs sanitized (no passwords, tokens)
- [ ] Error messages safe (no stack traces to clients)
- [ ] Correlation IDs for tracing
- [ ] HTTPS ready (X-Forwarded-Proto header handling)

---

## LOGGING VERIFICATION

**Check logs contain**:

```
âœ… Request started: method, path, query, user-agent
âœ… Request completed: method, path, status, duration
âœ… Correlation ID on every log entry
âœ… User ID (if authenticated)
âœ… Module/service name
âœ… Timestamp (ISO format)

âœ… Error logs with: stack trace, context, correlation ID
âœ… Database queries: operation, duration, table
âœ… Business events: what happened, who, when

âŒ No passwords, tokens, API keys
âŒ No sensitive PII
âŒ No internal implementation details exposed to client
```

---

## METRICS VERIFICATION

**Verify metrics are recorded**:

```
âœ… http_requests_total (counter by method, path, status)
âœ… http_request_duration_ms (histogram with buckets)
âœ… errors_total (counter by code, path)
âœ… database_query_duration_ms (by operation, table)
âœ… Cache hits/misses (by cache name)

Performance:
âœ… Metrics collection has <1ms overhead
âœ… Prometheus scraping completes in <1s
```

---

## PERFORMANCE TARGETS

| Operation | Target | Measurement |
|-----------|--------|-------------|
| Log write | <1ms | Per log entry |
| Metrics record | <0.1ms | Per metric |
| Health check | <100ms | Database query included |
| Graceful shutdown | <30s | Full cleanup |
| Docker build | <2min | Multi-stage build |
| Docker image | <500MB | Size on disk |

---

## INTEGRATION WITH MONITORING

**After Phase 4, you can integrate**:

```
Prometheus Scraping:
  scrape_configs:
    - job_name: 'driftsentry'
      static_configs:
        - targets: ['localhost:3001']
      metrics_path: '/metrics'

Grafana Dashboards:
  âœ… Request rate (requests/sec)
  âœ… Response time (p50, p95, p99)
  âœ… Error rate (errors/sec)
  âœ… Database performance
  âœ… Memory usage

Alerting:
  âœ… High error rate (>5%)
  âœ… Slow requests (>1s)
  âœ… Database unavailable
  âœ… Pod restart loop
```

---

## PHASE 4: SUCCESS SIGNALS

You'll know Phase 4 is complete when:

```
Build & Startup:
  âœ… npm run type-check â†’ 0 errors
  âœ… npm run build â†’ succeeds
  âœ… npm run dev â†’ starts cleanly

Health Checks:
  âœ… /health/live â†’ 200 OK (always)
  âœ… /health/ready â†’ 200 OK (DB connected)
  âœ… /health/detailed â†’ 200 with memory, uptime

Logging:
  âœ… JSON format (not strings)
  âœ… Correlation IDs present
  âœ… All requests logged
  âœ… All errors logged
  âœ… No secrets logged

Metrics:
  âœ… /metrics endpoint returns data
  âœ… Prometheus format (text)
  âœ… Request metrics recorded
  âœ… Error metrics recorded
  âœ… Database metrics recorded

Docker:
  âœ… Dockerfile builds
  âœ… Image size <500MB
  âœ… Container runs
  âœ… App accessible on port 3001
  âœ… Health checks pass
  âœ… Logs are JSON
  âœ… Configuration validates

Shutdown:
  âœ… SIGTERM handled gracefully
  âœ… Database connections closed
  âœ… Server closes cleanly
  âœ… Exit code 0

Production Ready:
  âœ… Can be deployed to Kubernetes
  âœ… Can be deployed to Docker
  âœ… Can be monitored with Prometheus
  âœ… Can be debugged with correlation IDs
  âœ… Can scale horizontally
```

---

**Phase 4 Verified! Production-ready backend complete!** ğŸš€
